{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaef52f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pandas as  pd\n",
    "import os\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34801899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/susanbeale/anaconda3/envs/testing/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/Users/susanbeale/anaconda3/envs/testing/lib/python3.10/site-packages/torchvision/image.so, 6): Library not loaded: @rpath/libjpeg.8.dylib\n",
      "  Referenced from: /Users/susanbeale/anaconda3/envs/testing/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: image not found\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# code from ClimatExML to make batches etc. \n",
    "class ClimatExMLLoader(Dataset):\n",
    "    def __init__(self, lr_glob, hr_glob) -> None:\n",
    "        self.lr_glob = lr_glob\n",
    "        self.hr_glob = hr_glob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_glob[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr = torch.stack([torch.load(var[idx]) for var in self.lr_glob])\n",
    "        hr = torch.stack([torch.load(var[idx]) for var in self.hr_glob])     \n",
    "        return [lr, hr]\n",
    "\n",
    "\n",
    "class ClimatExMLData(pl.LightningDataModule):\n",
    "    def __init__(self, data_glob: dict = None, num_workers: int = 24, batch_size: int = None):\n",
    "        super().__init__()\n",
    "        self.data_glob = data_glob\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        self.test_data = ClimatExMLLoader(self.data_glob['lr_test'], self.data_glob['hr_test'])\n",
    "        self.train_data = ClimatExMLLoader(self.data_glob['lr_train'], self.data_glob['hr_train'])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_data, batch_size=self.batch_size, shuffle=True, num_workers=self.num_workers, pin_memory=True),\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # For some reason this can't be a dictionary?\n",
    "        return DataLoader(self.test_data, batch_size=self.batch_size, num_workers=self.num_workers, shuffle=False, pin_memory=True),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51da4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data \n",
    "\n",
    "lr_data_6 = {\n",
    "    \"lr_test\": ['/Volumes/LaCie/2year_scale_factor_4/test/uas/lr/*.pt','/Volumes/LaCie/2year_scale_factor_4/test/vas/lr/*.pt'],\n",
    "    \"lr_train\": ['/Volumes/LaCie/2year_scale_factor_4/train/uas/lr/*.pt','/Volumes/LaCie/2year_scale_factor_4/train/vas/lr/*.pt']\n",
    "}\n",
    "\n",
    "hr_data_6 = {\n",
    "    \"hr_test\": ['/Volumes/LaCie/2year_scale_factor_4/test/hs/hr/*.pt'],\n",
    "    \"hr_train\": ['/Volumes/LaCie/2year_scale_factor_4/train/hs/hr/*.pt']\n",
    "}\n",
    "data_6 = {\n",
    "    \"lr_train\": [glob.glob(path) for path in lr_data_6[\"lr_train\"]],\n",
    "    \"hr_train\": [glob.glob(path) for path in hr_data_6[\"hr_train\"]],\n",
    "    \"lr_test\": [glob.glob(path) for path in lr_data_6[\"lr_test\"]],\n",
    "    \"hr_test\": [glob.glob(path) for path in hr_data_6[\"hr_test\"]]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e27c608",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_data_16 = {\n",
    "    \"lr_test\": ['/Volumes/LaCie/2year_coarsened_cropped/test/uas/lr/*.pt','/Volumes/LaCie/2year_coarsened_cropped/test/vas/lr/*.pt'],\n",
    "    \"lr_train\": ['/Volumes/LaCie/2year_coarsened_cropped/train/uas/lr/*.pt','/Volumes/LaCie/2year_coarsened_cropped/train/vas/lr/*.pt']\n",
    "}\n",
    "\n",
    "hr_data_16 = {\n",
    "    \"hr_test\": ['/Volumes/LaCie/2year_coarsened_cropped/test/hs/hr/*.pt'],\n",
    "    \"hr_train\": ['/Volumes/LaCie/2year_coarsened_cropped/train/hs/hr/*.pt']\n",
    "}\n",
    "data_16 = {\n",
    "    \"lr_train\": [glob.glob(path) for path in lr_data_16[\"lr_train\"]],\n",
    "    \"hr_train\": [glob.glob(path) for path in hr_data_16[\"hr_train\"]],\n",
    "    \"lr_test\": [glob.glob(path) for path in lr_data_16[\"lr_test\"]],\n",
    "    \"hr_test\": [glob.glob(path) for path in hr_data_16[\"hr_test\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b1560b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  torch.Size([2, 32, 32]) output size:  torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# creates a list of tensors test_data[time stamp][input =0, output=1]\n",
    "test_data_6 = ClimatExMLLoader(data_6['lr_test'], data_6['hr_test'])\n",
    "input_size_6 = test_data_6[0][0].size()\n",
    "output_size_6 = test_data_6[0][1].size()\n",
    "print('input size: ', input_size_6, 'output size: ', output_size_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e13cea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  torch.Size([2, 16, 16]) output size:  torch.Size([1, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "test_data_16 = ClimatExMLLoader(data_16['lr_test'], data_16['hr_test'])\n",
    "input_size_16 = test_data_16[0][0].size()\n",
    "output_size_16 = test_data_16[0][1].size()\n",
    "print('input size: ', input_size_16, 'output size: ', output_size_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7927e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making arrays of data for input \n",
    "\n",
    "wind_6 = []\n",
    "hs_6 = []\n",
    "\n",
    "for i in range(len(test_data_6)):\n",
    "    wind_6.append(test_data_6[i][0].detach().numpy())\n",
    "    hs_6.append(test_data_6[i][1].detach().numpy())\n",
    "    \n",
    "w_6 = np.array(wind_6)\n",
    "# print(w[1])\n",
    "hs_6 = np.array(hs_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7174658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making arrays of data for input \n",
    "\n",
    "wind_16 = []\n",
    "hs_16 = []\n",
    "\n",
    "for i in range(len(test_data_16)):\n",
    "    wind_16.append(test_data_16[i][0].detach().numpy())\n",
    "    hs_16.append(test_data_16[i][1].detach().numpy())\n",
    "    \n",
    "w_16 = np.array(wind_16)\n",
    "# print(w[1])\n",
    "hs_16 = np.array(hs_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50954eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m l[i:i \u001b[38;5;241m+\u001b[39m n]\n\u001b[1;32m      8\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m---> 10\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(divide_chunks(\u001b[43mw\u001b[49m, batch_size))\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# print (x[0])\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "# separating data into batches \n",
    "def divide_chunks(l, n):\n",
    "      \n",
    "    # looping till length l\n",
    "    for i in range(0, len(l), n): \n",
    "        yield l[i:i + n]\n",
    "  \n",
    "batch_size = 8\n",
    "  \n",
    "x = list(divide_chunks(w, batch_size))\n",
    "# print (x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2147ce02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/07/06 13:52:36 WARNING mlflow.pyfunc: Detected one or more mismatches between the model's dependencies and the current Python environment:\n",
      " - mlflow (current: 2.3.2, required: mlflow==2.3)\n",
      "To fix the mismatches, call `mlflow.pyfunc.get_model_dependencies(model_uri)` to fetch the model's environment and install dependencies using the resulting environment file.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ClimatExML.mlflow_tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 19\u001b[0m\n\u001b[1;32m     13\u001b[0m model_path_16 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/susanbeale/desktop/climate_ml_artifacts/70b73c423e4a44f2918feb3b54950a0b/artifacts/model\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 6 residual blocks, 2 upsampling layers, coarsened wind input (scale_factor=4)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# model_path_6 = f'/Users/susanbeale/desktop/climate_ml_artifacts/6973409397724a43b61a61e03dc7cd70/artifacts/model'\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m model_16 \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path_16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# model_6 = mlflow.pyfunc.load_model(model_path_6)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[1;32m     23\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(sys.getsizeof(x))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# model.get_params()\u001b[39;00m\n\u001b[1;32m     29\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:596\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path)\u001b[0m\n\u001b[1;32m    594\u001b[0m _add_code_from_conf_to_system_path(local_path, conf, code_key\u001b[38;5;241m=\u001b[39mCODE)\n\u001b[1;32m    595\u001b[0m data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(local_path, conf[DATA]) \u001b[38;5;28;01mif\u001b[39;00m (DATA \u001b[38;5;129;01min\u001b[39;00m conf) \u001b[38;5;28;01melse\u001b[39;00m local_path\n\u001b[0;32m--> 596\u001b[0m model_impl \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mMAIN\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pyfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m predict_fn \u001b[38;5;241m=\u001b[39m conf\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m PyFuncModel(model_meta\u001b[38;5;241m=\u001b[39mmodel_meta, model_impl\u001b[38;5;241m=\u001b[39mmodel_impl, predict_fn\u001b[38;5;241m=\u001b[39mpredict_fn)\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/mlflow/pytorch/__init__.py:751\u001b[0m, in \u001b[0;36m_load_pyfunc\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_pyfunc\u001b[39m(path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    746\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;124;03m    Load PyFunc implementation. Called by ``pyfunc.load_model``.\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \n\u001b[1;32m    749\u001b[0m \u001b[38;5;124;03m    :param path: Local filesystem path to the MLflow Model with the ``pytorch`` flavor.\u001b[39;00m\n\u001b[1;32m    750\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _PyTorchWrapper(\u001b[43m_load_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/mlflow/pytorch/__init__.py:657\u001b[0m, in \u001b[0;36m_load_model\u001b[0;34m(path, **kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Version(torch\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.5.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    659\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;66;03m# load the model as an eager model.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/torch/serialization.py:1165\u001b[0m, in \u001b[0;36m_load.<locals>.UnpicklerWrapper.find_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m mod_name \u001b[38;5;241m=\u001b[39m load_module_mapping\u001b[38;5;241m.\u001b[39mget(mod_name, mod_name)\n\u001b[0;32m-> 1165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/testing/lib/python3.10/site-packages/ClimatExML-0.1.0-py3.10.egg/ClimatExML/wgan_gp.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClimatExML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator, Critic\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClimatExML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlflow_tools\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmlflow_tools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     gen_grid_images,\n\u001b[1;32m      9\u001b[0m     log_metrics_every_n_steps,\n\u001b[1;32m     10\u001b[0m     log_pytorch_model,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClimatExML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClimatExMLLoader\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mClimatExML\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m content_loss, SSIM_Loss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ClimatExML.mlflow_tools'"
     ]
    }
   ],
   "source": [
    "# loading model\n",
    "import sys\n",
    "# 1 residual block\n",
    "# model_path = f'/Users/susanbeale/desktop/climate_ml_artifacts/db3c90c54b2e470db9f9bd6c41215eba/artifacts/model'\n",
    "\n",
    "# 0 residual blocks\n",
    "# model_path = f'/Users/susanbeale/desktop/climate_ml_artifacts/ec707a55bf66479791d89ef20d66c108/artifacts/model'\n",
    "\n",
    "# 1 residual block -> coarsened lr input\n",
    "# model_path = f'/Users/susanbeale/desktop/climate_ml_artifacts/10ea1abccd7d46fda0f8869cb0ccb72f/artifacts/model'\n",
    "\n",
    "# 16 residual blocks, 3 upsampling layers, coarsened wind input (scale_factor=8)\n",
    "model_path_16 = f'/Users/susanbeale/desktop/climate_ml_artifacts/70b73c423e4a44f2918feb3b54950a0b/artifacts/model'\n",
    "\n",
    "# 6 residual blocks, 2 upsampling layers, coarsened wind input (scale_factor=4)\n",
    "# model_path_6 = f'/Users/susanbeale/desktop/climate_ml_artifacts/6973409397724a43b61a61e03dc7cd70/artifacts/model'\n",
    "\n",
    "\n",
    "model_16 = mlflow.pyfunc.load_model(model_path_16)\n",
    "\n",
    "# model_6 = mlflow.pyfunc.load_model(model_path_6)\n",
    "\n",
    "\n",
    "# model_info = mlflow.models.get_model_info(model_path)\n",
    "\n",
    "\n",
    "# print(sys.getsizeof(x))\n",
    "# model.get_params()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7005e06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_6 = model_6.predict(w_6)\n",
    "pred_16 = model_16.predict(w_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1ee214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(x))\n",
    "print(pred_6.shape)\n",
    "print(hs_6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f6a8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred_16.shape)\n",
    "print(hs_16.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b2d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tens_16 = torch.from_numpy(pred_16)\n",
    "hs_tens_16 = torch.from_numpy(hs_16)\n",
    "w_tens_16 = torch.from_numpy(w_16)\n",
    "w_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a567790",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tens_6 = torch.from_numpy(pred_6)\n",
    "hs_tens_6 = torch.from_numpy(hs_6)\n",
    "w_tens_6 = torch.from_numpy(w_6)\n",
    "w_6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a7d059",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tens.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tens[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad71b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.psd(pred_tens_16, label='fake')\n",
    "plt.psd(hs_tens_16, label='real')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72721eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of truth, generated, and input images\n",
    "num_row = 5\n",
    "index = np.random.randint(0,hs_tens_6.size()[0], (num_row))\n",
    "index = index.astype(int)\n",
    "\n",
    "row = np.linspace(0,num_row-1, num_row)\n",
    "row = row.astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(num_row, 4, figsize=(10, 10))\n",
    "ax[0,0].set_title('Truth')\n",
    "ax[0,1].set_title('CNN')\n",
    "ax[0,2].set_title('Wind Input')\n",
    "\n",
    "\n",
    "for i,j in zip(index,row):\n",
    "    ax[j,0].imshow(hs_tens_6[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,1].imshow(pred_tens_6[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,2].imshow(w_tens_6[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,3].imshow(w_tens_6[i, 1, ...].detach().cpu(), origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a946f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random selection of truth, generated, and input images\n",
    "num_row = 5\n",
    "index = np.random.randint(0,hs_tens_16.size()[0], (num_row))\n",
    "index = index.astype(int)\n",
    "\n",
    "row = np.linspace(0,num_row-1, num_row)\n",
    "row = row.astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(num_row, 4, figsize=(10, 10))\n",
    "ax[0,0].set_title('Truth')\n",
    "ax[0,1].set_title('CNN')\n",
    "ax[0,2].set_title('Wind Input')\n",
    "\n",
    "\n",
    "for i,j in zip(index,row):\n",
    "    ax[j,0].imshow(hs_tens_16[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,1].imshow(pred_tens_16[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,2].imshow(w_tens_16[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "    ax[j,3].imshow(w_tens_16[i, 1, ...].detach().cpu(), origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f760ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "i = np.random.randint(0,hs_tens_6.size()[0])\n",
    "ax[0].imshow(hs_tens_6[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "ax[0].set_title('Truth')\n",
    "ax[1].imshow(pred_tens_6[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "ax[1].set_title(\"CNN (6 residual blocks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc77c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "i = np.random.randint(0,hs_tens_16.size()[0])\n",
    "ax[0].imshow(hs_tens_16[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "ax[0].set_title('Truth')\n",
    "ax[1].imshow(pred_tens_16[i, 0, ...].detach().cpu(), origin=\"lower\")\n",
    "ax[1].set_title(\"CNN (16 residual blocks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7a89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from RAPSD\n",
    "\n",
    "from typing import Generator, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "\"\"\"This module contains functions that calculate the\n",
    "radially averaged power spectral density (RASPD)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def calculate_2dft(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Computes the fourier transform and returns the amplitudes\"\"\"\n",
    "    fourier_image = np.fft.fftn(image)\n",
    "    # fourier_image = torch.fft.fftn(image)\n",
    "    fourier_amplitudes = np.abs(fourier_image)**2\n",
    "    # fourier_amplitudes = torch.abs(fourier_image)**2\n",
    "\n",
    "    return fourier_amplitudes.flatten()\n",
    "\n",
    "\n",
    "def define_wavenumers(hr_dim: int) -> np.ndarray:\n",
    "    \"\"\"Defines the wavenumbers for the RASPD\"\"\"\n",
    "    kfreq = np.fft.fftfreq(hr_dim)*hr_dim\n",
    "    kfreq2D = np.meshgrid(kfreq, kfreq)\n",
    "    knrm = np.sqrt(kfreq2D[0]**2 + kfreq2D[1]**2)\n",
    "    return knrm.flatten()\n",
    "\n",
    "\n",
    "def get_mean_bins(x, var_idx, knrm) -> Tuple:\n",
    "    \"\"\"Calculates the mean bins for the RASPD\"\"\"\n",
    "    kbins = np.arange(0.5, x.shape[-1]//2+1, 1.)\n",
    "    kvals = 0.5 * (kbins[1:] + kbins[:-1])\n",
    "    wind_2d = calculate_2dft(x[var_idx, ...].cpu().detach().numpy())\n",
    "    average_bins, _, _ = stats.binned_statistic(\n",
    "        knrm, wind_2d, statistic=\"mean\", bins=kbins\n",
    "        )\n",
    "    average_bins *= np.pi * (kbins[1:]**2 - kbins[:-1]**2)\n",
    "    return average_bins, kvals\n",
    "\n",
    "\n",
    "def compute_rapsd(\n",
    "        hr_field: Generator,\n",
    "        var_ref: dict = None,\n",
    "        reduce=True\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Computes the RASPD for a given super-resolution model\"\"\"\n",
    "\n",
    "    if var_ref is None:\n",
    "        var_ref = {\"hs\": 0}\n",
    "\n",
    "    var_rapsd = {}\n",
    "    [var_rapsd.setdefault(x, []) for x in var_ref]\n",
    "\n",
    "    for x in hr_field:\n",
    "        for var_name, var_idx in var_ref.items():\n",
    "            knrm = define_wavenumers(x.shape[-1])\n",
    "            average_bins, kvals = get_mean_bins(x, var_idx, knrm)\n",
    "            var_rapsd[var_name].append(average_bins)\n",
    "\n",
    "    var_rapsd_avg = {\"k\": kvals}\n",
    "    for var_name in var_ref:\n",
    "        if reduce:\n",
    "            var_rapsd_avg[var_name] = np.mean(\n",
    "                np.array(var_rapsd[var_name]),\n",
    "                axis=0\n",
    "            )\n",
    "        else:\n",
    "            var_rapsd_avg[var_name] = var_rapsd[var_name]\n",
    "\n",
    "    return var_rapsd_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519caf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_6 = compute_rapsd(pred_tens_6)\n",
    "real_6 = compute_rapsd(hs_tens_6)\n",
    "fake_mean_6 = np.mean(fake_6['hs'])\n",
    "real_mean_6 = np.mean(real_6['hs'])\n",
    "norm_fake_6 = fake_6['hs']/fake_mean_6\n",
    "norm_real_6 = real_6['hs']/real_mean_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e45ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_16 = compute_rapsd(pred_tens_16)\n",
    "real_16 = compute_rapsd(hs_tens_16)\n",
    "fake_mean_16 = np.mean(fake_16['hs'])\n",
    "real_mean_16 = np.mean(real_16['hs'])\n",
    "norm_fake_16 = fake_16['hs']/fake_mean_16\n",
    "norm_real_16 = real_16['hs']/real_mean_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9852c71c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "# closer to horizontal line is better\n",
    "# lack of power especially at small spatial scales\n",
    "# bias???? lack of power \n",
    "# ax.plot(fake_6['k'], fake_6['hs']/real_6['hs'], label='fake (6 residual blocks)')\n",
    "ax.plot(real_16['k'], real_16['hs']/real_16['hs'], label='real')\n",
    "ax.plot(fake_16['k'], fake_16['hs']/real_16['hs'], label='fake (16 residual blocks)')\n",
    "# ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.ylabel('RAPSD')\n",
    "plt.xlabel('wave #')\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf835ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax = plt.subplots()\n",
    "# left hand sidfe -> large scale smoothly varying spatial structure/patterns\n",
    "# to right -> increase spatial frequencies (wave number) -> measuring variability in small scale fluctuations\n",
    "# ax.plot(fake_6['k'], fake_6['hs'], label='fake (6 residual blocks)')\n",
    "ax.plot(real_16['k'], real_16['hs'], label='real')\n",
    "ax.plot(fake_16['k'], fake_16['hs'], label='fake (16 residual blocks)')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54f220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "mse = F.mse_loss(pred_tens_16, hs_tens_16)\n",
    "mae = F.l1_loss(pred_tens_16, hs_tens_16)\n",
    "print('mse: ', mse, 'mae: ', mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42589e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_tens_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdde629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ClimatExML.wgan_gp import SuperResolutionWGANGP\n",
    "# from lightning.pytorch.tuner import Tuner\n",
    "# from lightning.pytorch.loggers import MLFlowLogger\n",
    "\n",
    "# mlf_logger = MLFlowLogger(experiment_name=\"ClimatEx WGAN-GP\", tracking_uri=\"sqlite:////Users/susanbeale/desktop/climate_ml_artifacts/climatexdb.sqlite\")\n",
    "\n",
    "# clim_data = ClimatExMLData(data_glob=data, batch_size=1, num_workers=8)\n",
    "\n",
    "# srmodel = SuperResolutionWGANGP(clim_data)\n",
    "# trainer = pl.Trainer(precision=\"32\", accelerator=\"cpu\", max_epochs=1, logger=mlf_logger, log_every_n_steps=50)#fast_dev_run=True)\n",
    "# tuner = Tuner(trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# trainer.fit(srmodel)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c22fb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testing",
   "language": "python",
   "name": "testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
